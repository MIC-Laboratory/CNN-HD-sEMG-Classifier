{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of depolying CNN gensture reconition model to edge device (e.g. Sony Spresense)\n",
    "\n",
    "Step Overview:\n",
    "1. Conver Pytorch Model to Onnx Model\n",
    "2. Conver Onnx Model to Keras Model\n",
    "3. Conver Keras Model to quantization aware model\n",
    "4. Retraining quantization aware model\n",
    "5. Convert it to Tensorflow Lite Model\n",
    "6. Convert the model to hex header file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Representive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "config = json.load(open('config.json', 'r'))\n",
    "# Load input data from a MATLAB file\n",
    "for i in range(1,9):\n",
    "    input_data = scipy.io.loadmat(os.path.join(config[\"data_path\"],f\"001-00{i}-005.mat\"))['Data']\n",
    "\n",
    "    # Convert the input data to a PyTorch tensor\n",
    "    input_data = torch.asarray(input_data)\n",
    "    if input_data.shape[1] == 193:\n",
    "        input_data = input_data[:,:-1]\n",
    "    # Reshape the input data to match the expected shape of the model\n",
    "    input_data = input_data.reshape(-1, 1, 8, 24)\n",
    "\n",
    "    input_data = input_data.cpu().detach().numpy()\n",
    "\n",
    "    np.save(f\"representive_data_{i-1}\",input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conver Pytorch Model to Onnx Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from models.mobilenetv1 import MobilenetV1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "dummy_input = torch.randn(1, 1, 8, 24, device=device)\n",
    "model = MobilenetV1(ch_in=1, n_classes=8, Global_ratio=0.3).to(device)\n",
    "model.load_state_dict(torch.load(\n",
    "    \"pretrain_model/0.3MobilenetV1_Param@303.31 k_MAC@524.1 KMac_Acc@95.761.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# print(model)\n",
    "torch.onnx.export(model, dummy_input,\n",
    "                  \"pretrain_model/onnx_model/MobilenetV1.onnx\", verbose=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conver Onnx Model to Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install library\n",
    "%cd onnx2keras\n",
    "!pip install -e .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"pretrain_model/onnx_model/MobilenetV1.onnx\")\n",
    "from onnx2keras import onnx_to_keras\n",
    "model = onnx_to_keras(onnx_model, ['input.1'],name_policy='renumerate',verbose=False,change_ordering=True)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "q_aware_model = quantize_model(model)\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from utils.ICE_lab_data_preprocessing import ICE_lab_data_preprocessing as utils\n",
    "\n",
    "data,label,num_classes = utils().extra_data(\"data/Training_Trimmed\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, testing_data, training_label, testing_label = train_test_split(data, label, test_size=0.33, random_state=42)\n",
    "train_data = tf.data.Dataset.from_tensor_slices((training_data, training_label))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((testing_data, testing_label))\n",
    "\n",
    "training_data = training_data.reshape(-1,8,24,1)\n",
    "testing_data = testing_data.reshape(-1,8,24,1)\n",
    "q_aware_model.fit(training_data,training_label,\n",
    "                  batch_size=1000, epochs=2)\n",
    "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
    "   testing_data, testing_label, batch_size=1000,verbose=True)\n",
    "print('Quant test accuracy:', q_aware_model_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_model.save(\"pretrain_model/q_ware_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert it to Tensorflow Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def representative_dataset():\n",
    "    data = np.load(\"representive_data_0.npy\")\n",
    "    for i in range(1):\n",
    "        temp_data = data[i]\n",
    "        temp_data = temp_data.reshape(1,8,24,1)\n",
    "        yield [temp_data.astype(np.float32)]\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"pretrain_model/q_ware_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.float32  # or tf.uint8\n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "tflite_model_size = len(tflite_model) / 1024\n",
    "print('Quantized model size = %dKBs.' % tflite_model_size)\n",
    "# Save the model\n",
    "with open(\"pretrain_model/tf_lite_model/mobilenetv1.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"pretrain_model/tf_lite_model/mobilenetv1.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data\n",
    "input_shape = input_details[0]['shape']\n",
    "# input_data = np.array(np.random.random_sample(input_shape), dtype=np.int8)\n",
    "for j in range(8):\n",
    "    ori_input_data = np.load(f\"representive_data_{j}.npy\")\n",
    "    ori_input_data = ori_input_data.astype(np.float32)\n",
    "    # ori_input_data = ori_input_data.reshape(-1,8,24,1)\n",
    "    correct = 0\n",
    "    print(\"Total Sample Size:\",ori_input_data.shape[0])\n",
    "    for i in range(ori_input_data.shape[0]):\n",
    "        input_data = np.expand_dims(ori_input_data[i], 0)\n",
    "        input_data = input_data.reshape(-1,8,24,1)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # get_tensor() returns a copy of the tensor data\n",
    "        # use tensor() in order to get a pointer to the tensor\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        if np.argmax(output_data) == j:\n",
    "            correct += 1\n",
    "    print(\"Prediction Correct Size:\",correct) #Total:30720\n",
    "    print(\"Accuracy\",round(correct/int(ori_input_data.shape[0]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TFlite file to hex header file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "def convert_to_c_array(bytes) -> str:\n",
    "  hexstr = binascii.hexlify(bytes).decode(\"UTF-8\")\n",
    "  hexstr = hexstr.upper()\n",
    "  array = [\"0x\" + hexstr[i:i + 2] for i in range(0, len(hexstr), 2)]\n",
    "  array = [array[i:i+10] for i in range(0, len(array), 10)]\n",
    "  return \",\\n  \".join([\", \".join(e) for e in array])\n",
    "\n",
    "tflite_binary = open('pretrain_model/tf_lite_model/mobilenetv1.tflite', 'rb').read()\n",
    "ascii_bytes = convert_to_c_array(tflite_binary)\n",
    "header_file = \"const unsigned char model_tflite[] = {\\n  \" + ascii_bytes + \"\\n};\\nunsigned int model_tflite_len = \" + str(len(tflite_binary)) + \";\"\n",
    "with open(\"pretrain_model/tf_lite_model/model.h\", \"w\") as f:\n",
    "    f.write(header_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sEMG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
