{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an implementation of depolying CNN gensture reconition model to edge device (e.g. Sony Spresense)\n",
    "\n",
    "Step Overview:\n",
    "1. Conver Pytorch Model to Onnx Model\n",
    "2. Conver Onnx Model to Keras Model\n",
    "3. Conver Keras Model to quantization aware model\n",
    "4. Retraining quantization aware model\n",
    "5. Convert it to Tensorflow Lite Model\n",
    "6. Using Edge Impuls to generate code for Sony Spresense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conver Pytorch Model to Onnx Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studenta/anaconda3/envs/sEMG/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'input_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m dummy_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m24\u001b[39m, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m----> 6\u001b[0m model \u001b[39m=\u001b[39m MobilenetV1(input_layer\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, num_classes\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(\n\u001b[1;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpretrain_model/MobilenetV1_Param@29.29 k _MAC@233.1 KMac_Acc@95.346.pt\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      9\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'input_layer'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from models.mobilenetv1 import MobilenetV1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "dummy_input = torch.randn(1, 1, 8, 24, device=device)\n",
    "model = MobilenetV1(ch_in=1, n_classes=8).to(device)\n",
    "model.load_state_dict(torch.load(\n",
    "    \"pretrain_model/MobilenetV1_Param@29.29 k _MAC@233.1 KMac_Acc@95.346.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# print(model)\n",
    "torch.onnx.export(model, dummy_input,\n",
    "                  \"pretrain_model/onnx_model/MobilenetV1.onnx\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from models.mobilenetv2_no_bn import MobileNetV2\n",
    "dummy_input = torch.randn(1, 3, 300, 300, device=\"cuda\")\n",
    "# model = MobileNetV2(input_layer=1,num_classes=8,model_width=0.2).cuda()\n",
    "# model.load_state_dict(torch.load(\"pretrain_model_test/MobilenetV2_Param@231.760K_MAC@1.855M_Acc@96.236.pt\"), strict=False)\n",
    "# model.eval()\n",
    "model = torch.load('ssd.model')\n",
    "\n",
    "# print(model)\n",
    "torch.onnx.export(model, dummy_input, \"ssd.onnx\", verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conver Onnx Model to Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install library\n",
    "%cd onnx2keras\n",
    "!pip install -e .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "import tensorflow as tf\n",
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"pretrain_model_test/onnx_model/MobilenetV2.onnx\")\n",
    "from onnx2keras import onnx_to_keras\n",
    "model = onnx_to_keras(onnx_model, ['input.1'],name_policy='renumerate',verbose=False,change_ordering=True)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "q_aware_model = quantize_model(model)\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from utils.ICE_lab_data_preprocessing import ICE_lab_data_preprocessing as utils\n",
    "\n",
    "data,label,num_classes = utils().extra_data(\"data/Training_Trimmed\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, testing_data, training_label, testing_label = train_test_split(data, label, test_size=0.33, random_state=42)\n",
    "train_data = tf.data.Dataset.from_tensor_slices((training_data, training_label))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((testing_data, testing_label))\n",
    "\n",
    "training_data = training_data.reshape(-1,8,24,1)\n",
    "testing_data = testing_data.reshape(-1,8,24,1)\n",
    "training_data = utils().NormalizeData(training_data)\n",
    "testing_data = utils().NormalizeData(testing_data)\n",
    "q_aware_model.fit(training_data,training_label,\n",
    "                  batch_size=1000, epochs=2)\n",
    "_, q_aware_model_accuracy = q_aware_model.evaluate(\n",
    "   testing_data, testing_label, batch_size=1000,verbose=True)\n",
    "print('Quant test accuracy:', q_aware_model_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_model.save(\"pretrain_model_test/q_ware_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert it to Tensorflow Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def representative_dataset():\n",
    "    data = np.load(\"representive_data.npy\")\n",
    "    for i in range(1):\n",
    "        temp_data = data[i]\n",
    "        temp_data = temp_data.reshape(1,8,24,1)\n",
    "        yield [temp_data.astype(np.float32)]\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"pretrain_model_test/q_ware_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "with open(\"pretrain_model_test/tf_lite_model/mobilenetv2.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=\"pretrain_model_test/tf_lite_model/mobilenetv2.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data\n",
    "input_shape = input_details[0]['shape']\n",
    "# input_data = np.array(np.random.random_sample(input_shape), dtype=np.int8)\n",
    "for j in range(2,9):\n",
    "    ori_input_data = np.load(f\"representive_data{j}.npy\")\n",
    "    ori_input_data = ori_input_data.astype(np.int8)\n",
    "    # ori_input_data = ori_input_data.reshape(-1,8,24,1)\n",
    "    correct = 0\n",
    "    print(\"Total Sample Size:\",ori_input_data.shape[0])\n",
    "    for i in range(ori_input_data.shape[0]):\n",
    "        input_data = np.expand_dims(ori_input_data[i], 0)\n",
    "        input_data = input_data.reshape(-1,8,24,1)\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # get_tensor() returns a copy of the tensor data\n",
    "        # use tensor() in order to get a pointer to the tensor\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        if np.argmax(output_data) == j-1:\n",
    "            correct += 1\n",
    "    print(\"Prediction Correct Size:\",correct) #Total:30720\n",
    "    print(\"Accuracy\",round(correct/int(ori_input_data.shape[0]),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sEMG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
